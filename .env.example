# vLLM Configuration
MODEL_NAME=Qwen/Qwen2.5-14B-Instruct
MAX_MODEL_LEN=16384
GPU_MEMORY_UTILIZATION=0.90
DTYPE=auto

# API Keys (change these to secure values!)
VLLM_API_KEY=your-vllm-api-key-here
WEBUI_SECRET_KEY=your-webui-secret-key-here

# Open WebUI Settings
ENABLE_SIGNUP=false
DEFAULT_USER_ROLE=pending
ENABLE_COMMUNITY_SHARING=false

# Optional: Hugging Face token for gated models
HUGGING_FACE_TOKEN=